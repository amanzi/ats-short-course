{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3059ae87-5f5c-409c-b216-167261f1dca1",
   "metadata": {},
   "source": [
    "# Write ATS input file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee695604-3f49-44a7-abcf-a5486382dd50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "We now generate three input files -- two for spinup (steadystate solution and cyclic steadystate solution) and one for transient runs.\n",
    "\n",
    "* Input files: ATS xml files\n",
    "  - `{WATERSHED_NAME}_spinup-steadystate.xml` the steady-state solution based on uniform application of mean rainfall rate\n",
    "  - `{WATERSHED_NAME}_spinup-cyclic_steadystate.xml` the cyclic steady state based on typical years\n",
    "  - `{WATERSHED_NAME}_transient.xml` the forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06330b40-3a79-46ee-9e9e-2e497062831e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe8dfc-db29-4ad2-a579-307ef284f4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, yaml, pickle, datetime\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s: %(message)s')\n",
    "\n",
    "# ats_input_spec library, to be moved to amanzi_xml\n",
    "import ats_input_spec\n",
    "import ats_input_spec.public\n",
    "import ats_input_spec.io\n",
    "\n",
    "# amanzi_xml, included in AMANZI_SRC_DIR/tools/amanzi_xml\n",
    "import amanzi_xml.utils.io as aio\n",
    "import amanzi_xml.utils.search as asearch\n",
    "import amanzi_xml.utils.errors as aerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf9344-f8d5-46d4-adc2-b771b719f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('.', 'input_data')\n",
    "def toInput(filename):\n",
    "    return os.path.join(data_dir, filename)\n",
    "\n",
    "output_dir = os.path.join('.', 'output_data')\n",
    "def toOutput(filename):\n",
    "    return os.path.join(output_dir, filename)\n",
    "\n",
    "work_dir = os.path.join('.')\n",
    "def toWorkingDir(filename):\n",
    "    return os.path.join(work_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccaf4ce-aea4-4c76-8ada-dad467aac24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'Coweeta'\n",
    "# config_fname = f'../../data/examples/{watershed_name}/processed/config.yaml'\n",
    "watershed_latitude = 35 # the average latitude of the watershed in degree, used for calculating incident radiation\n",
    "nyears_cyclic_steadystate = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c90b4-51ed-4f95-be22-2cf691f5c0b7",
   "metadata": {},
   "source": [
    "## load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf49872-6870-4fdc-a0ae-d61cb1171a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_files_path = './intermediate_files/output_files.pkl'\n",
    "with open(out_files_path, 'rb') as f:\n",
    "    output_filenames = pickle.load(f)\n",
    "display(output_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ae157-0e93-40e6-9b2a-dd867d8da620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle files\n",
    "intermediate_dir = './intermediate_files/'\n",
    "with open(f'{intermediate_dir}m2.pkl', 'rb') as file:\n",
    "    m2 = pickle.load(file)\n",
    "with open(f'{intermediate_dir}m3.pkl', 'rb') as file:\n",
    "    m3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb2413-dce6-4e97-896d-ebda3c916381",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip_mean = output_filenames['mean_precip [m s^-1]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ab071-360b-4f38-be30-67ea9b400257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlcd_indices = output_filenames['nlcd_indices']\n",
    "nlcd_labels = output_filenames['nlcd_labels']\n",
    "nlcd_labels_dict = dict(zip(nlcd_indices, nlcd_labels))\n",
    "start = datetime.datetime.strptime(output_filenames['start'], \"%Y-%m-%d\") \n",
    "end = datetime.datetime.strptime(output_filenames['end'], \"%Y-%m-%d\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295a0e4-ba17-4902-9f8e-ced30b94dbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load subsurface properties\n",
    "subsurface_props_used = pd.read_csv(output_filenames['subsurface_properties'], index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99e31b-a02d-4ea4-9493-d96d4c672a70",
   "metadata": {},
   "source": [
    "## Write input files\n",
    "\n",
    "Replace template files with generated watershed specific properties. This also sets the start and end date of the simulations, and creates directories for each run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a35d7-2f69-4c40-8c83-c5e1f726dea4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "- `{name}_spinup_steadystate.xml`: For the first file, we load a spinup template and write the needed quantities into that file, saving it to the appropriate run directory.  Note there is no DayMet or land cover or LAI properties needed for this run.  The only property that is needed is the domain-averaged, mean annual rainfall rate.  We then take off some for ET (note too wet spins up faster than too dry, so don't take off too much...).\n",
    "\n",
    "- `{name}_spinup_cyclic.xml`: For the second file, we load a transient run template.  This file needs the basics, plus DayMet and LAI as the \"typical year data\".  Also we set the run directory that will be used for the steadystate run.\n",
    "\n",
    "- `{name}_transient.xml`: For the third file, we load a transient run template as well.  This file needs the basics, DayMet with the actual data, and we choose for this run to use the MODIS typical year.  MODIS is only available for 2002 on, so if we didn't need 1980-2002 we could use the real data, but for this run we want a longer record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627548e-6760-40dc-8b3d-7df8a612ae99",
   "metadata": {
    "papermill": {
     "duration": 1.143055,
     "end_time": "2022-03-07T15:59:14.911795",
     "exception": false,
     "start_time": "2022-03-07T15:59:13.768740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note that each of these are defined as functions so we can reuse them for all three input files.\n",
    "\n",
    "# add the subsurface and surface domains\n",
    "#\n",
    "# Note this also adds a \"computational domain\" region to the region list, and a vis spec \n",
    "# for \"domain\"\n",
    "def add_domains(main_list, mesh, surface_region='surface', snow=True, canopy=True):\n",
    "    ats_input_spec.public.add_domain(main_list, \n",
    "                                 domain_name='domain', \n",
    "                                 dimension=3, \n",
    "                                 mesh_type='read mesh file',\n",
    "                                 mesh_args={'file':mesh})\n",
    "    if surface_region:\n",
    "        main_list['mesh']['domain']['build columns from set'] = surface_region    \n",
    "    \n",
    "        # Note this also adds a \"surface domain\" region to the region list and a vis spec for \n",
    "        # \"surface\"\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='surface',\n",
    "                                dimension=2,\n",
    "                                mesh_type='surface',\n",
    "                                mesh_args={'surface sideset name':'surface'})\n",
    "    if snow:\n",
    "        # Add the snow and canopy domains, which are aliases to the surface\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='snow',\n",
    "                                dimension=2,\n",
    "                                mesh_type='aliased',\n",
    "                                mesh_args={'target':'surface'})\n",
    "    if canopy:\n",
    "        ats_input_spec.public.add_domain(main_list,\n",
    "                                domain_name='canopy',\n",
    "                                dimension=2,\n",
    "                                mesh_type='aliased',\n",
    "                                mesh_args={'target':'surface'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e2af2-db4f-4992-b95d-2f2ff5b7f67d",
   "metadata": {
    "papermill": {
     "duration": 1.135431,
     "end_time": "2022-03-07T15:59:17.151867",
     "exception": false,
     "start_time": "2022-03-07T15:59:16.016436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_land_cover(main_list):\n",
    "    # next write a land-cover section for each NLCD type\n",
    "    for index, nlcd_name in zip(nlcd_indices, nlcd_labels):\n",
    "        ats_input_spec.public.set_land_cover_default_constants(main_list, nlcd_name)\n",
    "\n",
    "    land_cover_list = main_list['state']['model parameters']['land cover types']\n",
    "    # update some defaults for\n",
    "    # ['Other', 'Deciduous Forest']\n",
    "    # note, these are from the CLM Technical Note v4.5\n",
    "    #\n",
    "    # Rooting depth curves from CLM TN 4.5 table 8.3\n",
    "    #\n",
    "    # Note, the mafic potential values are likely pretty bad for the types of van Genuchten \n",
    "    # curves we are using (ETC -- add paper citation about this topic).  Likely they need\n",
    "    # to be modified.  Note that these values are in [mm] from CLM TN 4.5 table 8.1, so the \n",
    "    # factor of 10 converts to [Pa]\n",
    "    #\n",
    "    # Note, albedo of canopy taken from CLM TN 4.5 table 3.1\n",
    "    land_cover_list['Deciduous Forest']['rooting profile alpha [-]'] = 6.0\n",
    "    land_cover_list['Deciduous Forest']['rooting profile beta [-]'] = 2.0\n",
    "    land_cover_list['Deciduous Forest']['rooting depth max [m]'] = 10.0\n",
    "    land_cover_list['Deciduous Forest']['capillary pressure at fully closed stomata [Pa]'] = 224000\n",
    "    land_cover_list['Deciduous Forest']['capillary pressure at fully open stomata [Pa]'] = 35000 * .10\n",
    "    land_cover_list['Deciduous Forest']['albedo of canopy [-]'] = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48556791-eaeb-4009-9fec-6241705891c0",
   "metadata": {
    "papermill": {
     "duration": 1.421863,
     "end_time": "2022-03-07T15:59:19.669461",
     "exception": false,
     "start_time": "2022-03-07T15:59:18.247598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add soil sets: note we need a way to name the set, so we use, e.g. SSURGO-MUKEY.\n",
    "def soil_set_name(ats_id):\n",
    "    return subsurface_props_used.loc[ats_id, 'name']\n",
    "\n",
    "def add_soil_properties(main_list):\n",
    "    # add soil material ID regions, porosity, permeability, and WRMs\n",
    "    for ats_id in subsurface_props_used.index:\n",
    "        props = subsurface_props_used.loc[ats_id]\n",
    "        set_name = soil_set_name(ats_id)\n",
    "        \n",
    "        if props['van Genuchten n [-]'] < 1.5:\n",
    "            smoothing_interval = 0.01\n",
    "        else:\n",
    "            smoothing_interval = 0.0\n",
    "        \n",
    "        ats_input_spec.public.add_soil_type(main_list, set_name, ats_id, output_filenames['mesh'],\n",
    "                                            float(props['porosity [-]']),\n",
    "                                            float(props['permeability [m^2]']), 1.e-7,\n",
    "                                            float(props['van Genuchten alpha [Pa^-1]']),\n",
    "                                            float(props['van Genuchten n [-]']),\n",
    "                                            float(props['residual saturation [-]']),\n",
    "                                            float(smoothing_interval))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a7c0e6-3533-4861-b1f2-91b0682294f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an ATS \"main\" input spec list -- note, this is a dummy and is not used to write any files yet\n",
    "def get_main(steadystate=False):\n",
    "    main_list = ats_input_spec.public.get_main()\n",
    "\n",
    "    # add the mesh and all domains\n",
    "    mesh = os.path.join('..', output_filenames['mesh'])\n",
    "    add_domains(main_list, mesh)\n",
    "\n",
    "    # add labeled sets\n",
    "    for ls in m3.labeled_sets:\n",
    "        ats_input_spec.public.add_region_labeled_set(main_list, ls.name, ls.setid, mesh, ls.entity)\n",
    "    for ss in m3.side_sets:\n",
    "        ats_input_spec.public.add_region_labeled_set(main_list, ss.name, ss.setid, mesh, 'FACE')\n",
    "    \n",
    "    # add land cover\n",
    "    add_land_cover(main_list)\n",
    "\n",
    "    # add soil properties\n",
    "    add_soil_properties(main_list)\n",
    "        \n",
    "    # add observations for each subcatchment\n",
    "    if steadystate:\n",
    "        time_args = {'cycles start period stop':[0,10,-1],}\n",
    "    else:\n",
    "        time_args = None\n",
    "    ats_input_spec.public.add_observations_water_balance(main_list, \"computational domain\", \n",
    "                                                        \"surface domain\", \"external sides\",\n",
    "                                                        time_args=time_args)\n",
    "\n",
    "    return main_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55ebd9-3407-483f-9f28-b609b8806847",
   "metadata": {
    "papermill": {
     "duration": 1.152786,
     "end_time": "2022-03-07T15:59:21.928795",
     "exception": false,
     "start_time": "2022-03-07T15:59:20.776009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def populate_basic_properties(xml, main_xml):\n",
    "    \"\"\"This function updates an xml object with the above properties for mesh, regions, soil props, and lc props\"\"\"\n",
    "    # find and replace the mesh list\n",
    "    xml.replace('mesh', asearch.child_by_name(main_xml, 'mesh'))\n",
    "\n",
    "    # find and replace the regions list\n",
    "    xml.replace('regions', asearch.child_by_name(main_xml, 'regions'))\n",
    "\n",
    "    # update the observations list\n",
    "    obs = next(i for (i,el) in enumerate(xml) if el.get('name') == 'observations')\n",
    "    xml[obs] = asearch.child_by_name(main_xml, 'observations')\n",
    "\n",
    "    # update all model parameters lists\n",
    "    xml_parlist = asearch.find_path(xml, ['state', 'model parameters'], no_skip=True)\n",
    "    for parlist in asearch.find_path(main_xml, ['state', 'model parameters'], no_skip=True):\n",
    "        try:\n",
    "            xml_parlist.replace(parlist.getName(), parlist)\n",
    "        except aerrors.MissingXMLError:\n",
    "            xml_parlist.append(parlist)\n",
    "\n",
    "    # update all evaluator lists\n",
    "    xml_elist = asearch.find_path(xml, ['state', 'evaluators'], no_skip=True)\n",
    "    for elist in asearch.find_path(main_xml, ['state', 'evaluators'], no_skip=True):\n",
    "        try:\n",
    "            xml_elist.replace(elist.getName(), elist)\n",
    "        except aerrors.MissingXMLError:\n",
    "            xml_elist.append(elist)    \n",
    "    \n",
    "    # find and replace land cover\n",
    "    mp_list = asearch.find_path(xml, ['state', 'model parameters'], no_skip=True)\n",
    "    lc_list = asearch.find_path(main_xml, ['state', 'model parameters', 'land cover types'], no_skip=True)\n",
    "    \n",
    "    try:\n",
    "        mp_list.replace('land cover types', lc_list)\n",
    "    except aerrors.MissingXMLError:\n",
    "        mp_list.append(lc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cfffe9-a2b9-449e-805d-36428da5745e",
   "metadata": {
    "papermill": {
     "duration": 1.368452,
     "end_time": "2022-03-07T16:00:03.262110",
     "exception": false,
     "start_time": "2022-03-07T16:00:01.893658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_spinup_steadystate(name, precip_mean, **kwargs):\n",
    "    # create the main list\n",
    "    main = get_main()\n",
    "\n",
    "    # set precip to 0.6 * the mean precip value\n",
    "    precip = main['state']['evaluators'].append_empty('surface-precipitation')\n",
    "    precip.set_type('independent variable constant', ats_input_spec.public.known_specs['evaluator-independent-variable-constant-spec'])\n",
    "    precip['value'] = float(precip_mean * .6)\n",
    "\n",
    "    \n",
    "    # load the template file\n",
    "    prefix = 'steadystate'\n",
    "    xml = aio.fromFile(toInput(f'{prefix}-template.xml'))\n",
    "    \n",
    "    # update the template xml with the main xml generated here\n",
    "    main_xml = ats_input_spec.io.to_xml(main)\n",
    "    populate_basic_properties(xml, main_xml, **kwargs)\n",
    "\n",
    "    # write to disk\n",
    "    output_filenames[f'ats_xml_{prefix}'] = toWorkingDir(f'{name}-{prefix}.xml')\n",
    "    filename = output_filenames[f'ats_xml_{prefix}']\n",
    "    aio.toFile(xml, filename)\n",
    "\n",
    "    # create a run directory\n",
    "    output_filenames[f'ats_rundir_{prefix}'] = toWorkingDir(f'{name}-{prefix}')\n",
    "    rundir = output_filenames[f'ats_rundir_{prefix}']\n",
    "    os.makedirs(rundir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ce93d-1de1-4e3b-88ec-976e43721d9b",
   "metadata": {
    "papermill": {
     "duration": 1.155846,
     "end_time": "2022-03-07T16:00:10.035975",
     "exception": false,
     "start_time": "2022-03-07T16:00:08.880129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_transient(name, cyclic_steadystate=False, **kwargs):\n",
    "    # make a unique name based on options\n",
    "    logging.info(f'Writing transient: {name}')\n",
    "\n",
    "    if cyclic_steadystate:\n",
    "        prefix = 'cyclic_steadystate'\n",
    "        previous = 'steadystate'\n",
    "    else:\n",
    "        prefix = 'transient'\n",
    "        previous = 'cyclic_steadystate'\n",
    "\n",
    "    main = get_main()\n",
    "\n",
    "    # add the DayMet evaluators\n",
    "    if cyclic_steadystate:\n",
    "        daymet_filename = output_filenames['meteorology_cyclic_steadystate']\n",
    "    else:\n",
    "        daymet_filename = output_filenames['meteorology_transient']\n",
    "    ats_input_spec.public.add_daymet_box_evaluators(main, os.path.join('..', daymet_filename), True)\n",
    "\n",
    "    # add the LAI filenames\n",
    "    if cyclic_steadystate:\n",
    "        lai_filename = output_filenames['nlcd_lai_cyclic_steadystate']\n",
    "    else:\n",
    "        lai_filename = output_filenames['nlcd_lai_transient']\n",
    "    ats_input_spec.public.add_lai_point_evaluators(main, os.path.join('..', lai_filename), list(nlcd_labels_dict.values()))\n",
    "    \n",
    "    # load the template file\n",
    "    template_filename = toInput(f'{prefix}-template.xml')\n",
    "    xml = aio.fromFile(template_filename)\n",
    "\n",
    "    # update the template xml with the main xml generated here\n",
    "    main_xml = ats_input_spec.io.to_xml(main)\n",
    "    populate_basic_properties(xml, main_xml, **kwargs)\n",
    "    \n",
    "    # update the start and end time -- would be nice to set these in main, but it would be \n",
    "    # confusing as to when to copy them in populate_basic_properties and when not to do so.\n",
    "    start_day = 274\n",
    "    if cyclic_steadystate:\n",
    "        end_day = 274 + (nyears_cyclic_steadystate - 1) * 365 \n",
    "    else:\n",
    "        end_day = 274 + (end - start).days \n",
    "        \n",
    "    par = asearch.find_path(xml, ['cycle driver', 'start time'])\n",
    "    par.setValue(start_day)\n",
    "\n",
    "    par = asearch.find_path(xml, ['cycle driver', 'end time'])\n",
    "    par.setValue(end_day)\n",
    "    \n",
    "    # update the restart filenames\n",
    "    for var in asearch.findall_path(xml, ['initial conditions', 'restart file']):\n",
    "        var.setValue(os.path.join('..', output_filenames[f'ats_rundir_{previous}'], 'checkpoint_final.h5'))\n",
    "   \n",
    "    # write to disk and make a directory for running the run\n",
    "    output_filenames[f'ats_xml_{prefix}'] = toWorkingDir(f'{name}-{prefix}.xml')\n",
    "    filename = output_filenames[f'ats_xml_{prefix}']\n",
    "\n",
    "    output_filenames[f'ats_rundir_{prefix}'] = toWorkingDir(f'{name}-{prefix}')\n",
    "    rundir = output_filenames[f'ats_rundir_{prefix}']\n",
    "\n",
    "    aio.toFile(xml, filename)\n",
    "    os.makedirs(rundir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052a485-0687-47c4-b44a-94e1af2826db",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_spinup_steadystate(name, precip_mean)\n",
    "write_transient(name, True)\n",
    "write_transient(name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6291ea82-6594-40fe-85c7-f849bbc8d75c",
   "metadata": {
    "papermill": {
     "duration": 1.175505,
     "end_time": "2022-03-07T16:00:14.959351",
     "exception": false,
     "start_time": "2022-03-07T16:00:13.783846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info('this workflow is a total success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f01697-6bb2-4cb5-b3dd-43ec0a505cf0",
   "metadata": {},
   "source": [
    "## Completion and Summary\n",
    "\n",
    "After this is complete, the following should work:\n",
    "\n",
    "```\n",
    "cd /path/to/ww/examples/Coweeta/Coweeta-steadystate\n",
    "mpiexec -n 4 ats ../Coweeta-steadystate.xml &> out.log\n",
    "cd ../Coweeta-cyclic_steadystate\n",
    "mpiexec -n 4 ats ../Coweeta-cyclic_steadystate.xml &> out.log\n",
    "cd ../Coweeta-transient\n",
    "mpiexec -n 4 ats ../Coweeta-transient.xml &> out.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e6022-c3d9-4934-928e-37171beb522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the following files were generated during this run:\n",
    "# print(f'{\"role\":<35}: filename')\n",
    "# print('-'*34, ': ', '-'*50)\n",
    "# for k,v in output_filenames.items():\n",
    "#     vs = list(splitPathFull(v))\n",
    "#     if vs[-2] == 'Coweeta':\n",
    "#         v2 = vs[-1]\n",
    "#     else:\n",
    "#         v2 = os.path.join(vs[-2], vs[-1])\n",
    "    \n",
    "#     print(f'{k:<35}: {v2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f30974-a723-4fb8-9e77-2478ae840011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (watershed_workflow)",
   "language": "python",
   "name": "watershed_workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
